{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a57a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torchvision.ops import nms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1029807",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"C:/work/cs/pj/Thaifood_ObjectDetectionNClassification/datasets/food/runs/detect/train26/weights/best.pt\")  # path to your trained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1025a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop 1 จานได้\n",
    "def crop_from_results(results, image_paths, output_dir='cropped', conf_threshold=0.5, target_class=1):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, result in enumerate(results):\n",
    "        image_path = image_paths[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"❌ Failed to read {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Extract boxes, class IDs, and confidences\n",
    "        try:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2, conf]\n",
    "            class_ids = result.boxes.cls.cpu().numpy()\n",
    "            confidences = result.boxes.conf.cpu().numpy()\n",
    "        except AttributeError:\n",
    "            print(f\"❌ result[{idx}] is missing .boxes or attributes\")\n",
    "            continue\n",
    "\n",
    "        crop_count = 0\n",
    "        for i, (box, cls_id, conf) in enumerate(zip(boxes, class_ids, confidences)):\n",
    "            if conf < conf_threshold:\n",
    "                continue\n",
    "            if int(cls_id) != target_class:\n",
    "                continue  # skip other classes\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box[:4])\n",
    "            cropped = image[y1:y2, x1:x2]\n",
    "\n",
    "            basename = os.path.basename(image_path).split('.')[0]\n",
    "            out_path = os.path.join(output_dir, f\"{basename}_class{target_class}_crop{crop_count+1}.jpg\")\n",
    "            cv2.imwrite(out_path, cropped)\n",
    "            print(f\"✅ Saved: {out_path}\")\n",
    "            crop_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7468880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_all_dishes_with_torch_nms(results, image_paths, output_dir='cropped', conf_threshold=0.3, iou_threshold=0.5, class_names=None):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, result in enumerate(results):\n",
    "        image = result.orig_img\n",
    "        if image is None:\n",
    "            print(f\"❌ Failed to read image at index {idx}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            boxes = result.boxes.xyxy  # torch.Tensor [N, 4]\n",
    "            scores = result.boxes.conf  # torch.Tensor [N]\n",
    "            class_ids = result.boxes.cls.int()  # torch.Tensor [N]\n",
    "        except AttributeError:\n",
    "            print(f\"❌ result[{idx}] missing .boxes attributes\")\n",
    "            continue\n",
    "\n",
    "        basename = os.path.splitext(os.path.basename(image_paths[idx]))[0]\n",
    "\n",
    "        for class_id in class_ids.unique():\n",
    "            cls_mask = class_ids == class_id\n",
    "            cls_boxes = boxes[cls_mask]\n",
    "            cls_scores = scores[cls_mask]\n",
    "\n",
    "            # Apply NMS\n",
    "            keep = nms(cls_boxes, cls_scores, iou_threshold)\n",
    "\n",
    "            for crop_count, i in enumerate(keep):\n",
    "                if cls_scores[i] < conf_threshold:\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = map(int, cls_boxes[i].tolist())\n",
    "                crop = image[y1:y2, x1:x2]\n",
    "\n",
    "                class_name = f\"class{class_id}\"\n",
    "                if class_names and class_id < len(class_names):\n",
    "                    class_name = class_names[class_id]\n",
    "\n",
    "                save_path = os.path.join(output_dir, f\"{basename}_{class_name}_crop{crop_count+1}.jpg\")\n",
    "                cv2.imwrite(save_path, crop)\n",
    "                print(f\"✅ Saved: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bbb76fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate11.jpg: 640x512 11 dish1s, 220.5ms\n",
      "Speed: 5.2ms preprocess, 220.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "✅ Saved: cropped\\plate11_dish1_crop1.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop2.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop3.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop4.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop5.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop6.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop7.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop8.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop9.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop10.jpg\n",
      "✅ Saved: cropped\\plate11_dish1_crop11.jpg\n"
     ]
    }
   ],
   "source": [
    "# แก้pathก้ด้วยนะ ของกุใส่.ละมันหาไม่เจอ\n",
    "image_dir = r\"C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\"\n",
    "# อันนี้กุลองบางรูปนะ\n",
    "# image_names = [\"plate1.jpg\", \"plate2.jpg\", \"plate3.jpg\", \"plate4.jpg\", \"plate5.jpg\"]\n",
    "image_names = [\"plate11.jpg\"]\n",
    "\n",
    "image_paths = [os.path.join(image_dir, name) for name in image_names]\n",
    "\n",
    "# Make sure 'results' is already created with model(image_paths)\n",
    "# Then call:\n",
    "results = [model(os.path.join(image_dir, name))[0] for name in image_names]\n",
    "# crop_from_results(results, image_paths, target_class=1)  # dish2\n",
    "class_names = [\"dish1\", \"dish2\", \"plate\"]\n",
    "# crop_all_dishes_from_results(results, image_paths, class_names=class_names)\n",
    "crop_all_dishes_with_torch_nms(\n",
    "    results=results,\n",
    "    image_paths=image_paths,\n",
    "    output_dir=\"cropped\",\n",
    "    conf_threshold=0.3,\n",
    "    iou_threshold=0.5,\n",
    "    class_names=class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30135d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\output_plate1.jpg: 448x640 1 dish2, 54.6ms\n",
      "image 2/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\output_plate2.jpg: 448x640 1 dish1, 2 dish2s, 27.8ms\n",
      "image 3/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\output_plate3.jpg: 448x640 1 dish2, 27.9ms\n",
      "image 4/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\output_plate4.jpg: 448x640 1 dish2, 28.6ms\n",
      "image 5/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\output_plate5.jpg: 480x640 1 dish2, 34.0ms\n",
      "image 6/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\output_plate6.jpg: 448x640 1 dish1, 12 dish2s, 28.6ms\n",
      "image 7/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\output_plate7.jpg: 384x640 1 dish1, 1 dish2, 62.4ms\n",
      "image 8/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\output_plate8.jpg: 384x640 2 dish1s, 4 dish2s, 20.1ms\n",
      "image 9/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\output_plate9.jpg: 480x640 1 dish1, 5 dish2s, 28.1ms\n",
      "image 10/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate1.jpg: 448x640 1 dish2, 12.9ms\n",
      "image 11/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate10.jpg: 480x640 9 dish1s, 9 dish2s, 14.9ms\n",
      "image 12/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate11.jpg: 640x512 3 dish1s, 8 dish2s, 16.0ms\n",
      "image 13/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate2.jpg: 448x640 1 dish1, 1 dish2, 10.7ms\n",
      "image 14/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate3.jpg: 448x640 1 dish1, 1 dish2, 15.6ms\n",
      "image 15/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate4.jpg: 448x640 1 dish1, 1 dish2, 11.7ms\n",
      "image 16/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate5.jpg: 480x640 1 dish2, 12.7ms\n",
      "image 17/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate6.jpg: 448x640 12 dish1s, 11.4ms\n",
      "image 18/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate7.jpg: 384x640 8 dish1s, 10.3ms\n",
      "image 19/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate8.jpg: 384x640 2 dish1s, 2 dish2s, 9.9ms\n",
      "image 20/20 C:\\work\\cs\\pj\\Thaifood_ObjectDetectionNClassification\\datasets\\food\\traintest\\plate9.jpg: 480x640 3 dish1s, 2 dish2s, 11.2ms\n",
      "Speed: 2.5ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "<class 'list'>\n",
      "['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n"
     ]
    }
   ],
   "source": [
    "results = model(image_dir)\n",
    "print(type(results))\n",
    "print(dir(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ไม่น่าต้องใละ\n",
    "def yolo_to_xyxy(xc, yc, w, h, img_w, img_h):\n",
    "    x1 = int((xc - w / 2) * img_w)\n",
    "    y1 = int((yc - h / 2) * img_h)\n",
    "    x2 = int((xc + w / 2) * img_w)\n",
    "    y2 = int((yc + h / 2) * img_h)\n",
    "    return [x1, y1, x2, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9a5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (food)",
   "language": "python",
   "name": "food"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
